#!/bin/bash
#
#BSUB -W 120:00                          # 24 hours of walltime requested
#BSUB -n 1                            # number of tasks in job; we get (4 nodes x 40 CPU slots), one gpu node has 40 cpu slots
#BSUB -q gpu_p100                       # choose the queue to use: normal or large_memory
echo #BSUB -R "select[ngpus>0] rusage[ngpus_excl_p=1]"

source /gpfs/gpfs0/groups/chowdhury/fanlai/pytorch_install.sh
source activate mytorch

